{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Assignment 2: Milestone I Natural Language Processing\n",
    "## Task 2&3\n",
    "#### Student Name: Bharath Narayanan Venkatesh\n",
    "#### Student ID: s4033348\n",
    "\n",
    "\n",
    "Environment: Python 3 and Jupyter notebook\n",
    "\n",
    "Libraries used:\n",
    "* pandas\n",
    "* gensim.downloader\n",
    "* re\n",
    "* numpy\n",
    "* sklearn\n",
    "\n",
    "## Introduction\n",
    "For task 2, we are going to take that pre-processed csv and vocab.txt and generate different feature representations for clothing item reviews. This will help in enhancing text analysis and at the same time help in performing Machine Learning analysis.This is a very important part in NLP process.We will convert raw data to numerical data which can be used in ML tasks. We are performing 3 steps, Count vector which is bag of words, unweighted embeddings and Tfidf weighted embeddings.\n",
    "\n",
    "For task3, we are going to create a logistic regression based classification model to classify dress reviews based on their recommendation.We will combine the models we found in Task2 with logistic regression model and see which one performs best. Also logistic regression model uses different input combinations like title only, description only and combination of title and description to find whether adding more information improves the performance of the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing libraries "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from gensim.models import KeyedVectors\n",
    "import gensim.downloader as api\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from sklearn.model_selection import cross_val_score, KFold\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2. Generating Feature Representations for Clothing Items Reviews\n",
    "1. I am first loading vocab.txt into a dictionary and processed.csv files to get Processed_Review column.\n",
    "2. Preparing Count Vector: We are creating a empty list to store the bag of words. The code then iterates through each review and a dictionary is used to count the occurrences of each word.This is then formatted as word_index:frequency.\n",
    "3. Pre-trained fasttext word embedding model is loaded.\n",
    "4. I am using this fasttext to calculate unweighted embeddings in Processed_Review column. The function get_unweighted_embedding calculates the mean word vectors from Processed_Review column.\n",
    "5. I am initializing TfidfVectorizer using vocab.txt to calculate Term Frequency and Inverse Document Frequency for Processed_Review column. I am defining a get_weighted_embedding function to calculate weighted_embedding for all review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading vocabulary\n",
    "vocab = {}\n",
    "with open('vocab.txt', 'r') as f:\n",
    "    for line in f:\n",
    "        word, index = line.strip().split(':')\n",
    "        vocab[word] = int(index)\n",
    "\n",
    "# Loading processed reviews from processed.csv file\n",
    "df = pd.read_csv('processed.csv')  \n",
    "\n",
    "# Handling missing values\n",
    "df['Processed_Review'] = df['Processed_Review'].astype(str).fillna('')\n",
    "\n",
    "# Preparing count vector(bag of words)\n",
    "sparse_count_vectors = []  \n",
    "for idx, review in enumerate(df['Processed_Review']):\n",
    "    if isinstance(review, str) and review.strip():\n",
    "        words = review.split()\n",
    "        word_freq = defaultdict(int)\n",
    "        for word in words:\n",
    "            if word in vocab:\n",
    "                word_freq[vocab[word]] += 1\n",
    "\n",
    "# Formatting the count vector in word_index:frequency\n",
    "        sparse_rep = ','.join([f'{word_idx}:{freq}' for word_idx, freq in sorted(word_freq.items())])\n",
    "        if sparse_rep:  \n",
    "            sparse_count_vectors.append(f\"#{idx},{sparse_rep}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_model = api.load(\"fasttext-wiki-news-subwords-300\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining a function to calculate unweighted FastText embeddings\n",
    "def get_unweighted_embedding(review, model, embedding_dim=300):\n",
    "    words = review.split()  \n",
    "    word_vectors = [model[word] for word in words if word in model]  \n",
    "    \n",
    "    # Calculate the mean embedding if words are found\n",
    "    if len(word_vectors) > 0:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    else:\n",
    "        return np.zeros(embedding_dim)\n",
    "\n",
    "# Generating unweighted embeddings for each review using Processed_Review column\n",
    "unweighted_embeddings = np.array([get_unweighted_embedding(review, embedding_model) for review in df['Processed_Review']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading vocabulary from vocab.txt\n",
    "vocab_dict = vocab  \n",
    "\n",
    "# Extracting reviews from DataFrame\n",
    "reviews = df['Processed_Review']\n",
    "\n",
    "# Initializing TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer(vocabulary=vocab_dict)\n",
    "tfidf_matrix = tfidf_vectorizer.fit_transform(reviews)\n",
    "\n",
    "# Getting feature names and their TF-IDF scores\n",
    "feature_names = tfidf_vectorizer.get_feature_names_out()\n",
    "tfidf_scores = tfidf_matrix.toarray()\n",
    "\n",
    "# Function to calculate TF-IDF weighted embeddings\n",
    "def get_weighted_embedding(review, model, tfidf_scores, feature_names, embedding_dim=300):\n",
    "    words = review.split()  \n",
    "    word_vectors = []\n",
    "    weights = []\n",
    "    \n",
    "    for word in words:\n",
    "        if word in model and word in feature_names:\n",
    "            word_idx = np.where(feature_names == word)[0][0]\n",
    "            word_vector = model[word]\n",
    "            tfidf_weight = tfidf_scores[word_idx]\n",
    "            word_vectors.append(word_vector)\n",
    "            weights.append(tfidf_weight)\n",
    "    \n",
    "    if len(word_vectors) > 0:\n",
    "        weighted_embedding = np.average(word_vectors, axis=0, weights=weights)\n",
    "        return weighted_embedding\n",
    "    else:\n",
    "        return np.zeros(embedding_dim)\n",
    "\n",
    "# Generating TF-IDF weighted embeddings for each review\n",
    "weighted_embeddings = np.array([get_weighted_embedding(review, embedding_model, tfidf_scores[i], feature_names, embedding_dim=300) for i, review in enumerate(reviews)])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving outputs\n",
    "I am saving these nparray based unweighted_embeddings and weighted_embeddings to a text named unweighted_embeddings.txt and tfidf_weighted_embeddings.txt and finally creating a file named count_vectors.txt to write all the sparse_count_vectors list to that file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Saving unweighted embeddings\n",
    "np.savetxt('unweighted_embeddings.txt', unweighted_embeddings, delimiter=',')\n",
    "\n",
    "# Saving weighted embeddings\n",
    "np.savetxt('tfidf_weighted_embeddings.txt', weighted_embeddings, delimiter=',')\n",
    "\n",
    "# Saving sparse_count_vectors to count_vectors.txt\n",
    "with open('count_vectors.txt', 'w') as outfile:\n",
    "    outfile.writelines(sparse_count_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 3. Clothing Review Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. We are extracting Title and Processed_Review columns from df and target variable is Recommended IND and concatinating title and description into a single feature named X_combined.\n",
    "2. I am creating a Logistic Regression Model with maximum iteration of 1000. 5 fold Cross validation is performed to evaluate the performance of the model using count vector and target variable.We are calculating the accuracy of the model. The model correctly predicted 88.10% of the time across different folds. \n",
    "3. I am loading the weighted_embeddings np array. The model is uses TF-IDF weighted embeddings and I am performing the same 5 fold Cross validation to compute the accuracy of the model based on this TF-IDF weighted embeddings data. The model correctly predicted 82.91% from the 5 fold cv.\n",
    "4. I am loading the unweighted_embeddings np array. Based on this data, the model predicted a accuracy percentage of 82.80%.\n",
    "5. I am using tfidf_vectorizer to generate TF-IDF features for title of clothing review. We are using the same Logistic Regression Model and again performing 5 fold Cross validation on the data to get the accuracy of the model. This yields a percentage of 88.29%. \n",
    "6. I am generating TF-IDF features for processed review description. The Logistic Regression Model gives 88.25% of accuracy.\n",
    "7. I am creating a new column in df named combined_text to concatinate Title and Processed_Review Description. The Logistic Regression Model for this data gives a accuracy of 89.84%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_title = df['Title'].fillna('')  \n",
    "X_description = df['Processed_Review'].fillna('')  \n",
    "y = df['Recommended IND']  \n",
    "\n",
    "# Combining title and description\n",
    "X_combined = X_title + \" \" + X_description "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Count Vector (Processed_Review) - 5-Fold CV Accuracy: 0.8810\n"
     ]
    }
   ],
   "source": [
    "with open('vocab.txt', 'r') as f:\n",
    "    vocab = {line.split(':')[0]: int(line.split(':')[1]) for line in f}\n",
    "\n",
    "# Initializing CountVectorizer\n",
    "count_vectorizer = CountVectorizer(vocabulary=vocab)\n",
    "X_count = count_vectorizer.fit_transform(X_description)\n",
    "\n",
    "# Logistic Regression Model\n",
    "log_reg = LogisticRegression(max_iter=1000)\n",
    "\n",
    "# 5-fold cross-validation\n",
    "kf = KFold(n_splits=5)\n",
    "cv_scores = cross_val_score(log_reg, X_count, y, cv=kf, scoring='accuracy')\n",
    "\n",
    "print(f\"Count Vector (Processed_Review) - 5-Fold CV Accuracy: {cv_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TF-IDF Weighted Embedding (Processed_Review) - 5-Fold CV Accuracy: 0.8291\n"
     ]
    }
   ],
   "source": [
    "X_tfidf_weighted = weighted_embeddings\n",
    "\n",
    "# 5-fold cross-validation\n",
    "cv_scores = cross_val_score(log_reg, X_tfidf_weighted, y, cv=kf, scoring='accuracy')\n",
    "\n",
    "# Print results\n",
    "print(f\"TF-IDF Weighted Embedding (Processed_Review) - 5-Fold CV Accuracy: {cv_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unweighted Embedding (Processed_Review) - 5-Fold CV Accuracy: 0.8280\n"
     ]
    }
   ],
   "source": [
    "X_unweighted = unweighted_embeddings\n",
    "\n",
    "cv_scores = cross_val_score(log_reg, X_unweighted, y, cv=kf, scoring='accuracy')\n",
    "\n",
    "print(f\"Unweighted Embedding (Processed_Review) - 5-Fold CV Accuracy: {cv_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title Only - 5-Fold CV Accuracy: 0.8829\n"
     ]
    }
   ],
   "source": [
    "# Generating TF-IDF features for title\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_title_tfidf = tfidf_vectorizer.fit_transform(X_title)\n",
    "\n",
    "# 5-fold cross-validation\n",
    "cv_scores = cross_val_score(log_reg, X_title_tfidf, y, cv=kf, scoring='accuracy')\n",
    "print(f\"Title Only - 5-Fold CV Accuracy: {cv_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed_Review (Description Only) - 5-Fold CV Accuracy: 0.8825\n"
     ]
    }
   ],
   "source": [
    "# Generating TF-IDF features for Processed_Review (description)\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_description_tfidf = tfidf_vectorizer.fit_transform(X_description)\n",
    "\n",
    "cv_scores = cross_val_score(log_reg, X_description_tfidf, y, cv=kf, scoring='accuracy')\n",
    "print(f\"Processed_Review (Description Only) - 5-Fold CV Accuracy: {cv_scores.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined Title and Processed_Review - 5-Fold CV Accuracy: 0.8984\n"
     ]
    }
   ],
   "source": [
    "# Concatenating Title and Processed_Review\n",
    "df['combined_text'] = df['Title'].fillna('') + ' ' + df['Processed_Review'].fillna('')\n",
    "\n",
    "# Generating TF-IDF features\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "X_combined_tfidf = tfidf_vectorizer.fit_transform(df['combined_text'])\n",
    "\n",
    "cv_scores_combined = cross_val_score(log_reg, X_combined_tfidf, y, cv=kf, scoring='accuracy')\n",
    "print(f\"Combined Title and Processed_Review - 5-Fold CV Accuracy: {cv_scores_combined.mean():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "To answer to Question 1 in the assignment specification, Count Vector outshines the remaining weighted and unweighted word embeddings. The model's accuracy percentage is 88.10 which is high when compared to other 2 models percentage. This shows that Count Vector model correctly identifies the main features of clothing review than other 2 models.\n",
    "\n",
    "For Question 2 in the assignment specification, the concatination of Title and Description has higher accuracy percentage of 89.84% when compared to their separate percentage accuracy. So, the additional inputs from both the features improves models performance compared to using each feature lonely.\n",
    "\n",
    "For task 2, we have generated Feature Representations for Clothing Items Reviews. We have used count vector model and fasttext word embedding based weighted and unweighted TF-IDF model. They were evaluated using Logistic Regression Model with Bag of words model coming out with highest accuracy.\n",
    "\n",
    "For task3, we have deployed Logistic Regression Model on Title, Description and combination of Title and Description and the accuracy of combination of Title and description came out to be higher when compared to their individual model accuracy percentage."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference \n",
    "1. https://www.kaggle.com/datasets/danielwillgeorge/glove6b100dtxt\n",
    "2. https://stackoverflow.com/questions/42002859/creating-a-tf-idf-matrix-python-3-6\n",
    "3. Scikit-learn. (n.d.). sklearn.feature_extraction.text.TfidfVectorizer. Retrieved September 27, 2024, from https://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
